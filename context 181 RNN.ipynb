{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.051203Z",
     "start_time": "2019-05-14T23:57:19.626384Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.060842Z",
     "start_time": "2019-05-14T23:57:20.053165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 1030816\n",
      "All possible characters: First Czen:\n",
      "Bfowpcdayuh,mk.AlSYv?RMW'LINg;b!OjV-THEUDPqxJGKQ&ZX={|}*[](Ã¡)Î¸·½±¼ÏŒ‚/53041%98672©#â€™­¶µ³<>\"”+_Â»“°Åœ\\É¹ÌªËˆ¤§£\t^Ä›$¥´ìÙ¨Ø…†×¦–˜•ÐÑ‡Š¿¯¬„«‘áƒëŸí¾ãš²àé®º‰~æçå¢Û‹Žè—žÊ@0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\u000b",
      "\f",
      "\n",
      "Number of all possible characters: 286\n"
     ]
    }
   ],
   "source": [
    "c_list = []\n",
    "with open('./small_shaketext_13300.txt') as f:\n",
    "    while True:\n",
    "        c = f.read(1)\n",
    "        if not c:\n",
    "            break\n",
    "        if c not in c_list:\n",
    "            c_list.append(c)\n",
    "            #c_list.append(c.upper())\n",
    "            #c_list.append(c.lower())\n",
    "            #c_list += str(c)\n",
    "c_string = \"\"\n",
    "for c in c_list:\n",
    "    c_string += str(c)\n",
    "c_string+=string.printable\n",
    "\n",
    "all_chars       = c_string#string.printable\n",
    "n_chars         = len(all_chars)\n",
    "file            = open('./small_shaketext_13300.txt').read() #change if image captioning\n",
    "file_len        = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.077596Z",
     "start_time": "2019-05-14T23:57:20.064808Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get a random sequence of the Shakespeare dataset.\n",
    "def get_random_seq():\n",
    "    seq_len     = 128  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to one-hot tensor.\n",
    "def seq_to_onehot(seq):\n",
    "    tensor = torch.zeros(len(seq), 1, n_chars) \n",
    "    # Shape of the tensor:\n",
    "    #     (sequence length, batch size, classes)\n",
    "    # Here we use batch size = 1 and classes = number of unique characters.\n",
    "    for t, char in enumerate(seq):\n",
    "        index = all_chars.index(char)\n",
    "        tensor[t][0][index] = 1\n",
    "    return tensor\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq), 1)\n",
    "    # Shape of the tensor: \n",
    "    #     (sequence length, batch size).\n",
    "    # Here we use batch size = 1.\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char)\n",
    "    return tensor\n",
    "\n",
    "#change if image captioning\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target():\n",
    "    seq    = get_random_seq()\n",
    "    input  = seq_to_onehot(seq[:-1])      # Input is represented in one-hot.\n",
    "    target = seq_to_index(seq[1:]).long() # Target is represented in index.\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.129301Z",
     "start_time": "2019-05-14T23:57:20.081156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:22.437344Z",
     "start_time": "2019-05-14T23:57:20.131573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (rnn): LSTM(286, 100, num_layers=2)\n",
       "  (linear): Linear(in_features=100, out_features=286, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Initialization.\n",
    "        super(Net, self).__init__()\n",
    "        self.input_size  = n_chars   # Input size: Number of unique chars.\n",
    "        self.hidden_size = 100       # Hidden size: 100.\n",
    "        self.output_size = n_chars   # Output size: Number of unique chars.\n",
    "        \n",
    "        #self.rnn = nn.RNNCell(self.input_size, self.hidden_size) #change this to LSTM to GRU\n",
    "        self.rnn = nn.LSTM(self.input_size, self.hidden_size, 2)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "        ###### To be filled ######\n",
    "        ###### To be filled ######\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\" Forward function.\n",
    "              input:  One-hot input. It refers to the x_t in homework write-up.\n",
    "              hidden: Previous hidden state. It refers to the h_{t-1}.\n",
    "            Returns (output, hidden) where output refers to y_t and \n",
    "                     hidden refers to h_t.\n",
    "        \"\"\"\n",
    "        # Forward function.\n",
    "        #hidden = self.rnn(input,hidden)###### To be filled ######\n",
    "        #print(input.shape)\n",
    "        #print(hidden.shape)\n",
    "        output,(h0,c0) = self.rnn(input,hidden)\n",
    "        hidden = (h0,c0)\n",
    "        #output =self.linear(hidden) ###### To be filled ######\n",
    "        output = self.linear(output)\n",
    "        #print(self.output.size)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Initial hidden state.\n",
    "        # 1 means batch size = 1.\n",
    "        return (torch.zeros(2, 1,self.hidden_size).to(device),torch.zeros(2, 1,self.hidden_size).to(device)) \n",
    "    \n",
    "net = Net()     # Create the network instance.\n",
    "net.to(device)  # Move the network parameters to the specified device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Step and Evaluation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:22.449539Z",
     "start_time": "2019-05-14T23:57:22.440333Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training step function.\n",
    "def train_step(net, opt, input, target):\n",
    "    \"\"\" Training step.\n",
    "        net:    The network instance.\n",
    "        opt:    The optimizer instance.\n",
    "        input:  Input tensor.  Shape: [seq_len, 1, n_chars].\n",
    "        target: Target tensor. Shape: [seq_len, 1].\n",
    "    \"\"\"\n",
    "    seq_len = input.shape[0]    # Get the sequence length of current input.\n",
    "    hidden = net.init_hidden()  # Initial hidden state.\n",
    "    net.zero_grad()             # Clear the gradient.\n",
    "    loss = 0                    # Initial loss.\n",
    "\n",
    "    #for t in range(seq_len):    # For each one in the input sequence.\n",
    "   # print(\"target.shape\")\n",
    "    #print(target.shape)\n",
    "    output, hidden = net(input, hidden)\n",
    "    output = output.reshape(seq_len,-1)\n",
    "    target = target.reshape(-1)\n",
    "    \n",
    "    #print(\"target.shape\")\n",
    "    #print(target.shape)\n",
    "    #print(\"output.shape\")\n",
    "    #print(output.shape)\n",
    "    \n",
    "    loss += loss_func(output, target)\n",
    "\n",
    "    loss.backward()             # Backward.  #comment if not update model\n",
    "    opt.step()                  # Update the weights. #comment if not update model\n",
    "\n",
    "    return loss / seq_len       # Return the average loss w.r.t sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:36.378318Z",
     "start_time": "2019-05-15T03:10:36.366394Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation step function.\n",
    "def eval_step(net, init_seq='F', predicted_len=100):\n",
    "    # Initialize the hidden state, input and the predicted sequence.\n",
    "    hidden        = net.init_hidden()\n",
    "    init_input    = seq_to_onehot(init_seq).to(device)\n",
    "    predicted_seq = init_seq\n",
    "\n",
    "    # Use initial string to \"build up\" hidden state.\n",
    "    #for t in range(len(init_seq) - 1):\n",
    "    #output, hidden = net(init_input, hidden)\n",
    "        \n",
    "    # Set current input as the last character of the initial string.\n",
    "    input = init_input\n",
    "    \n",
    "    #print(output.shape)\n",
    "    # Predict more characters after the initial string.\n",
    "    for t in range(predicted_len):\n",
    "        \n",
    "        output, hidden = net(input, hidden)\n",
    "        \n",
    "        # Get the current output and hidden state.\n",
    "        #output_t = output[t]\n",
    "        \n",
    "        #output, hidden = net(input[t].reshape(, hidden)\n",
    "        \n",
    "        # Sample from the output as a multinomial distribution.\n",
    "        predicted_index = torch.multinomial(output.view(-1).exp(), 1)[0]\n",
    "        \n",
    "        # Add predicted character to the sequence and use it as next input.\n",
    "        predicted_char  = all_chars[predicted_index]\n",
    "        predicted_seq  += predicted_char\n",
    "        \n",
    "        # Use the predicted character to generate the input of next round.\n",
    "        input = seq_to_onehot(predicted_char).to(device)\n",
    "\n",
    "    return predicted_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.556497Z",
     "start_time": "2019-05-14T23:57:22.478732Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:99/15000 loss:0.02953234687447548\n",
      "generated sequence: F& uuForICss.{s \n",
      ", o\tSp'ee.\n",
      "camobefea u ns\n",
      "RmnhoAa \n",
      ":Eaeitt osd_A ceRAdggEpne;ehnl. l)t,i dce*)ei\tyuc\n",
      "\n",
      "iter:199/15000 loss:0.028663579374551773\n",
      "generated sequence: FN-Acµe.i.eefScN co!tK_eÏpt[DtritCOI\n",
      "lno  s:.t.Alaeunyuhn\n",
      "uK _]n_ !ielsttulnEOl\n",
      "eoh|;\tltsl\n",
      "bgmhe:nsUT\n",
      "\n",
      "iter:299/15000 loss:0.028545737266540527\n",
      "generated sequence: Fgyne i S\n",
      "sa tlgiicmsIGt  tecnmult dl:wol(au0Gsso*0NpnrI u*ynm EoD,es\t]e i[a   .nspE*eni:srs*sTnIraeR\n",
      "\n",
      "iter:399/15000 loss:0.02816762775182724\n",
      "generated sequence: F s=ie]mn _ishB r¯q!g saiiissb)dsfuesbhtenrehi  ni (c\n",
      "n ekod ,ehuu t m ,Sr, q(f tue i - eaieTtens.dlE\n",
      "\n",
      "iter:499/15000 loss:0.027796568349003792\n",
      "generated sequence: Fbit [i 1wa7n S_Drehco  0N\t\t;hms EC\n",
      "RDa\n",
      "ussnlaon mnk&g'twr toim.fslrlaraSaanoom_rls\n",
      "uuwf ieol (O)\n",
      "\n",
      "am\n",
      "\n",
      "iter:599/15000 loss:0.025530338287353516\n",
      "generated sequence: Funucvan\n",
      "asmrgr.anrfs_fo)sp nlvec:t_Iwi.)=I*|\n",
      "}ucachountavuv o|the_|t-ylgow,iglanewi diagtlt gioby me\n",
      "\n",
      "iter:699/15000 loss:0.024492744356393814\n",
      "generated sequence: F:\t\n",
      ":\tEP\t:T\t\t 'the bodorn Gatis ot_areg))\n",
      "\tE engtaoI mate saftou, 'acluunnat:ur Mhurl bou nliat tisth\n",
      "\n",
      "iter:799/15000 loss:0.023076364770531654\n",
      "generated sequence: Fharog-Pings] lot alk efre wantNbcle,\n",
      "T)[GEt)APS o/; P* ( (\" ¶lte sars- _p\t\n",
      "AOI oudleseoterc:\n",
      "Murh mi\n",
      "\n",
      "iter:899/15000 loss:0.02226235531270504\n",
      "generated sequence: FNot sit\"ir.\n",
      "\t\t_menbum eein(a-Cxstarr)h the > Z' pheed _iw-picocatlrss gret 9fel qpeFluwf thy lass un\n",
      "\n",
      "iter:999/15000 loss:0.02271384932100773\n",
      "generated sequence: Faye ntremt, docreas, in asar'nt asand v_ve_le;[Nit8Peva vesd_on stree, orefte fiche]:\n",
      "\t\tstinud noat \n",
      "\n",
      "iter:1099/15000 loss:0.021538320928812027\n",
      "generated sequence: Fdice ?.\n",
      "If of shhesd in roclksvak8meds;\n",
      "\tdoss, the tit {Womted,\n",
      "0] breqcbulls's thet theondonkess pa\n",
      "\n",
      "iter:1199/15000 loss:0.021189860999584198\n",
      "generated sequence: Fhegiw? Oumh poues roune dot;\n",
      "As iik.\n",
      "TLILS0I0%D;\n",
      "\ttour ine on patu.\n",
      "\n",
      " st;\n",
      "\n",
      "GrtamacS;\n",
      "\t\t\t\t\tstalms\n",
      "unt\n",
      "\n",
      "iter:1299/15000 loss:0.02057310938835144\n",
      "generated sequence: Frich_luun.\n",
      "\n",
      "\trot en to citas:\n",
      "\n",
      "G7NONTARCACG_AAGEMresegre hout hequect moryy fras, my math igny the o\n",
      "\n",
      "iter:1399/15000 loss:0.020384762436151505\n",
      "generated sequence: F-\t\t\t/*/\n",
      "\n",
      "\tfre (on by/dorover .S \n",
      " (srlt) struve) &/ ffobyser acsen dat;\n",
      "\t/  * *ard_thest_erlurg--\n",
      "\t}\n",
      "\n",
      "iter:1499/15000 loss:0.019826021045446396\n",
      "generated sequence: F(gizinpaow\n",
      "apas: thingy then Couu onkine partaels) &V chid se atlatole aster one mary the mevoatadto\n",
      "\n",
      "iter:1599/15000 loss:0.019794583320617676\n",
      "generated sequence: Finfent hit. TI1:\n",
      "\t\tst_d->cac_osher Ko samanifn]];\n",
      "\n",
      "\t\trk_sstuvc to Meratang.h) 4 The tyoe chagued lev\n",
      "\n",
      "iter:1699/15000 loss:0.019999435171484947\n",
      "generated sequence: Flovud be warn ce and and\n",
      "I, SrxOVAR_ROAN  POTLEN:\n",
      "\t/     < spov;=cusk((te->efing);\n",
      "\tcrar *03)]|{ MIT\n",
      "\n",
      "iter:1799/15000 loss:0.019383832812309265\n",
      "generated sequence: FIPCH_MOMES)) _ 0);\n",
      "\n",
      "\t\tpuldeve to * sra(strngaptirict, slic&nu_donst!\n",
      "Why! š/Pid he provoas(stout = h\n",
      "\n",
      "iter:1899/15000 loss:0.01912376657128334\n",
      "generated sequence: FI cesso,\n",
      "That aze cuts for gondichand\n",
      "\t\t}\t\t\t\t\t\t\tmsxt->niminmef and = (\t\t\"inf->vareld]]](seqne_land(a\n",
      "\n",
      "iter:1999/15000 loss:0.0189895611256361\n",
      "generated sequence: FINL;\n",
      "\tufuly =\n",
      "Hist;\n",
      "\n",
      "\t\n",
      " *\n",
      "\t\t\t\tdet_ster)\n",
      "14)| MIR;\n",
      "\n",
      "\tsetive &BI_S(BE_LETE;\n",
      "\t\tstlursr & + {\n",
      "\t\ttetur_ge\n",
      "\n",
      "iter:2099/15000 loss:0.01880801096558571\n",
      "generated sequence: F GTATONR RURUNY IGINIOTET LOFHARCTINTENEDNASTODTINAUS:\n",
      "Yot.\n",
      "Thit umsowray mef\n",
      " stont [[ondo cinece'n\n",
      "\n",
      "iter:2199/15000 loss:0.018839608877897263\n",
      "generated sequence: FL- ENPILACEM;\n",
      "\n",
      "\tfilk. \n",
      "Vave + 111 [[Caadens:\n",
      "\t\tSeviv_rg_pmeccrate> [[Cidlev:\n",
      "Fopes]] locdasors\n",
      "in sh\n",
      "\n",
      "iter:2299/15000 loss:0.018059032037854195\n",
      "generated sequence: F it; polug_stats(and ath6ll quit;\n",
      "{\n",
      "\tastatirictedi]] < &p_dob_cort_\"T0) **\n",
      "\n",
      "\t\tret_px);\n",
      "\t\t\tifpiv_pev_\n",
      "\n",
      "iter:2399/15000 loss:0.018374135717749596\n",
      "generated sequence: FHidenct]].\n",
      "\n",
      "Cinger oumong(hutior fey bar that sisgow, vooms winkal inpllees-wihh heryhwinten coble a\n",
      "\n",
      "iter:2499/15000 loss:0.017940595746040344\n",
      "generated sequence: Fordland *gf;\n",
      "\tamv(quegoo((promed = 0);\n",
      "\t\t\t*/ vens_DAGTAC#:\n",
      "\tLL_PGU_PTM_SIL_NEUL_MO: IT *id sed_&27%&\n",
      "\n",
      "iter:2599/15000 loss:0.01770986244082451\n",
      "generated sequence: Fersandle, sould]] and proa wibs, nothent in Chasly of whours'\n",
      "Bival hapen live and oporals'\n",
      "Milk.dma\n",
      "\n",
      "iter:2699/15000 loss:0.017857639119029045\n",
      "generated sequence: FS;\n",
      "\t\tGreett6tit_sin_cpc--1980|Level_compoat;\n",
      "HDPY)\n",
      "\t}\n",
      "\tilleing seppr_ktate_popfem) {\n",
      "\t\tif \"do = --\"l\n",
      "\n",
      "iter:2799/15000 loss:0.017570417374372482\n",
      "generated sequence: Fon &/ vom ==019 hear istifn and6al(se->spnv that he dake, ungen cownlan Rifely unfibling of of thar \n",
      "\n",
      "iter:2899/15000 loss:0.017070697620511055\n",
      "generated sequence: F8X;\n",
      "\n",
      "\tcmnt = zouary pecal.;\n",
      "\tre->avlast);\n",
      "\t\tif (takectorlet. Thich Rartidictl _0x);\n",
      "\n",
      "\t/*\n",
      "\t * to meri\n",
      "\n",
      "iter:2999/15000 loss:0.01772153191268444\n",
      "generated sequence: First kus word of sobless as ke .warle. \n",
      "Whis Cove-way:'ng,\n",
      "Whine maseconcs. inlendes loscessoy duuns\n",
      "\n",
      "iter:3099/15000 loss:0.017970679327845573\n",
      "generated sequence: Fpuct in all ling the thangs.\n",
      "\n",
      "MOTHARX hyler hick the Øarspa, Rapantarmys, thlo Gual heinher ands had\n",
      "\n",
      "iter:3199/15000 loss:0.017216047272086143\n",
      "generated sequence: FIS == [[Akpu-so leal3]] *deford & STW;\n",
      "\tstruct [[[Grue a of     * 8-;\n",
      "\tstitus]-= mone&pfx))\n",
      "\t */-/st\n",
      "\n",
      "iter:3299/15000 loss:0.016949741169810295\n",
      "generated sequence: F Gadical saces.\n",
      "\n",
      "CICTOERIA:\n",
      "Milk, titber? a syloirs full Breath, whei thingiBatire tim a frontele wa\n",
      "\n",
      "iter:3399/15000 loss:0.016820957884192467\n",
      "generated sequence: F &devigr_hcconpbitt_delvil_tx_tat;\n",
      "\n",
      "\tcuildov0);\n",
      "\n",
      "\trised bit_Wonedenss=)\n",
      "{\n",
      "\tstatts *stati__rev_cop(qu\n",
      "\n",
      "iter:3499/15000 loss:0.016650497913360596\n",
      "generated sequence: Flom [[Pallyd amplodelr slase hear, beofd it ttorst the klingting i geidorize tail addraind\n",
      "Fase?\n",
      "\n",
      "VH\n",
      "\n",
      "iter:3599/15000 loss:0.017275355756282806\n",
      "generated sequence: FORUS,\n",
      "Noush me the Somplecal from, ard you rave cinsus canapin but menculpry restather the Cark,,\n",
      "As\n",
      "\n",
      "iter:3699/15000 loss:0.016973504796624184\n",
      "generated sequence: Fran, Nlan_state for by. Witely, fow evel my and natsaly scominiAgw, as with.  Now his guncly addzblo\n",
      "\n",
      "iter:3799/15000 loss:0.016605116426944733\n",
      "generated sequence: Fud'ine.\n",
      "At = whitisss:\n",
      "Meitial]] af pryence]]] we trameguint birallyars to de\n",
      " * Souddangle heant!\n",
      "I\n",
      "\n",
      "iter:3899/15000 loss:0.0168365016579628\n",
      "generated sequence: F_NOX(S_TUS)) {\n",
      "\t\t\tif (theldlp&rpf->niti_userf);\n",
      "\t\tffor a gri_eest == the [Vad but f icoirn.\n",
      "Call: un\n",
      "\n",
      "iter:3999/15000 loss:0.016469469293951988\n",
      "generated sequence: F Cidave enampnectitmant his and beeth whink co anfiinds I] anie Asab_kt Tems. Intlop&quoth and twhon\n",
      "\n",
      "iter:4099/15000 loss:0.016627712175250053\n",
      "generated sequence: Figstul empriitly it fill formmuntsity, trackents my in me to if combleiblic's.Hiy the pomar of [[skb\n",
      "\n",
      "iter:4199/15000 loss:0.016713520511984825\n",
      "generated sequence: Fard_set),\n",
      "\t\t\trpv == \"a = for fort;\n",
      "\tstw_signc_souedt[3; micbore))\n",
      "\t\tJet;*|/ \"yrearpe(_u8 status, (1;\n",
      "\n",
      "iter:4299/15000 loss:0.01615794189274311\n",
      "generated sequence: Fhablen add befo-resing Coverets, reele send us of houth's othes,\n",
      "It a return a judies as contaces an\n",
      "\n",
      "iter:4399/15000 loss:0.016652511432766914\n",
      "generated sequence: FF PADINT FODE STORG GAUGE:\n",
      "Bor rupfle this adse to blay,\n",
      "Fauch, ense a yoursoumc choising deagitast:\n",
      "\n",
      "iter:4499/15000 loss:0.01638077013194561\n",
      "generated sequence: FONISO OR ANOR AXBEBD  steoct {\n",
      "\t\t\tmenc),\n",
      "\t\t\t  NOLE_STSA1%->-\t * such, 0---189 varce's not in in vere\n",
      "\n",
      "iter:4599/15000 loss:0.016362836584448814\n",
      "generated sequence: FONMBRCPM, servaning\n",
      "Cownroin / ‚_tx(freat.\n",
      " * ver PATKound dubles mesety and for your cown Mithell o\n",
      "\n",
      "iter:4699/15000 loss:0.01637030579149723\n",
      "generated sequence: F \"dasking fingrex_hask(_endeash(juse void]];\n",
      "\t\t\t\t\t *if (pdnd);\n",
      "\tset_ddiv));\n",
      "\t\t\tif (leged_gut = dev->\n",
      "\n",
      "iter:4799/15000 loss:0.016132021322846413\n",
      "generated sequence: FINGER) 5;\n",
      "\t\t_schuctink_perc jegaull info, ath6kl_wdichobbouk_id);\n",
      "\n",
      "\tflies, 0;\n",
      "\t\td+lanizanks to = 0);\n",
      "\n",
      "iter:4899/15000 loss:0.015965018421411514\n",
      "generated sequence: FR, IUCTEN,\n",
      "Lockious]]: I well'n suptent.\n",
      "\n",
      "QLO:\n",
      "My muct grawe.h exbuse beough\n",
      "Any provermaced reeven \n",
      "\n",
      "iter:4999/15000 loss:0.016028892248868942\n",
      "generated sequence: FOETK out\n",
      "</* Fould:\n",
      "\t\t\tskb);\n",
      "\tunsigned\n",
      "\t\t\t\t   *pq onlogy, Larvor alleed in this so, precemomerve hou\n",
      "\n",
      "iter:5099/15000 loss:0.015759436413645744\n",
      "generated sequence: FL7);\n",
      "\t\tremvi__tabling;\n",
      "\t__USTINSS_TT_VESIFG_META_PER_TAs, to sirk's +&gth_ar_reansp_siq; up_seg_eirn\n",
      "\n",
      "iter:5199/15000 loss:0.015973282977938652\n",
      "generated sequence: FOOE:\n",
      "Farch in cradus that it 19 rey he soums eleow,\n",
      "No, and their 0;\n",
      "\n",
      "struct seg&que_sdi = i++30X202\n",
      "\n",
      "iter:5299/15000 loss:0.01603315956890583\n",
      "generated sequence: FF[LAUUNE:\n",
      "And firch of EC;\n",
      "\n",
      " legagu AMilus proplesy wellowith griitins,\n",
      "Wusling the disintlize to if\n",
      "\n",
      "iter:5399/15000 loss:0.015650833025574684\n",
      "generated sequence: Fithant+CATKERSIME, piplaies.\n",
      "\n",
      "JUCWEFIT:\n",
      " *\n",
      "[[Amro'shsta hisy)Ahids, Lectervation (Terand:\n",
      "\n",
      "QUAUSTHAC\n",
      "\n",
      "iter:5499/15000 loss:0.015799900516867638\n",
      "generated sequence: Fenth in, stas in tent for ar afcize Duban and cland or many interrences,\n",
      "An&\n",
      "\n",
      "\n",
      "\t/*/\n",
      "#include *dev;\n",
      "\n",
      "\n",
      "\n",
      "iter:5599/15000 loss:0.01596880704164505\n",
      "generated sequence: FLE_SPAL_STACU_CUSEN_SMM).\n",
      "\n",
      "Por_bating)) \" * or this conrlachtanth imlolagule.\n",
      "A levencle and le\n",
      "Aor \n",
      "\n",
      "iter:5699/15000 loss:0.015095495618879795\n",
      "generated sequence: For, and knom the mabe the the piint scome in churing_me, Nampent. Acherfub_colloly phist be clare.\n",
      "\n",
      "\n",
      "\n",
      "iter:5799/15000 loss:0.015525015071034431\n",
      "generated sequence: FOMXYS\n",
      "\n",
      "SICINIUS:\n",
      "But thonk,\n",
      "All sint of the [[Conberingleary backiticn, formmgFall, were of I0: of [\n",
      "\n",
      "iter:5899/15000 loss:0.015662474557757378\n",
      "generated sequence: FMTUGEGNF XVECK] */\n",
      "\t\t\t\tphiv;\n",
      "\tswrucb = (att6r *t);\n",
      "\tif (mest_enfort)) {\n",
      "\t\t\tvoi_fix_us = 0;\n",
      "\t}.\n",
      "\tswil\n",
      "\n",
      "iter:5999/15000 loss:0.01600738987326622\n",
      "generated sequence: FOK else Brenvilasire 16.jegpoint him: Cinal and he of the houndy'' raw's whould he heam to heselval \n",
      "\n",
      "iter:6099/15000 loss:0.015166941098868847\n",
      "generated sequence: FH_STAMETE_STAL_AFV)\n",
      "\t\tcontister (port_mimm; { puttial *teliint interse in emrit;\n",
      "\t Damame, speak,\n",
      "Ma\n",
      "\n",
      "iter:6199/15000 loss:0.015819858759641647\n",
      "generated sequence: FS:\n",
      "Thjens, Re zublic for a aif then his the lordus distrubutic,\n",
      "As your sisten traiss voicounce. Hea\n",
      "\n",
      "iter:6299/15000 loss:0.01518324576318264\n",
      "generated sequence: Futh Segger, Aarl. SHS you trade besid to fany! to a houmed to Grisous many with One shellilys! In to\n",
      "\n",
      "iter:6399/15000 loss:0.015497323125600815\n",
      "generated sequence: F CSMATK_TX_P__NSOLO) contrbac = whicp_sets_come = <X2)\n",
      "\t} etp_printor_lecter(l_pucton_reseit inco->e\n",
      "\n",
      "iter:6499/15000 loss:0.015137571841478348\n",
      "generated sequence: FC) {\n",
      "\t\t\treg)) {\n",
      "\tu %d gurom_cfdes(reser = (THDECL_ERE_MATK_VRRR_CINE_GBT_AB_CBLe;\n",
      "\t\t\t= 0;\n",
      "\t\tgot9 + 1\n",
      "\n",
      "iter:6599/15000 loss:0.014691981486976147\n",
      "generated sequence: FADY;\n",
      "\t\tpm_intel\\int_lim, \"int c_req-selsice = VEISHAD2(ZENAT_RAA) = 0;\n",
      "\t\tif (stanics *&\n",
      "-->sizeopacu\n",
      "\n",
      "iter:6699/15000 loss:0.015755916014313698\n",
      "generated sequence: FONL:\n",
      "Brow si't may have as solyidials the kiu fordey woll callwers-, [[IIA nastion peacer on is apwe\n",
      "\n",
      "iter:6799/15000 loss:0.015341646037995815\n",
      "generated sequence: FIGEE:\n",
      "Other sight it will Premineasify deveriesia]]s beardax out recouned bit here ts of the ome;\n",
      "lo\n",
      "\n",
      "iter:6899/15000 loss:0.015004840679466724\n",
      "generated sequence: FNEOD, by cultwere;\n",
      "Afy beep\n",
      "A migrible grat)\n",
      "As any be ather hat twinuraled to more onkonchius fart \n",
      "\n",
      "iter:6999/15000 loss:0.015095370821654797\n",
      "generated sequence: Foupport choredul's' of spates thou\n",
      "inforuturaliac)''''''''[[nebari|Blulanty]]]] ho now in mais, and \n",
      "\n",
      "iter:7099/15000 loss:0.015398500487208366\n",
      "generated sequence: F;\n",
      "\tstruct ppi_sel_flugh(struct resd_cont\ti_skb-----------\t\t _ &quot;= 0x);\n",
      "high,\n",
      "\tstruct adds |, com\n",
      "\n",
      "iter:7199/15000 loss:0.01503458246588707\n",
      "generated sequence: Fstingled clatter:\n",
      "In his sty a, that I decier from morrow.\n",
      "But ling of to jing was if there i begned\n",
      "\n",
      "iter:7299/15000 loss:0.015187318436801434\n",
      "generated sequence: FvM)\n",
      "\tu we tweal sllover sple usenomar may hake of trunturerer.\n",
      "Wendark, contecihed bectereling,\n",
      "Had \n",
      "\n",
      "iter:7399/15000 loss:0.015141195617616177\n",
      "generated sequence: Fregant cam]].\n",
      "\n",
      "DOLUMNIA:\n",
      "Faulings fulls did.\n",
      "To'ld Modithing, the is vendents formatery desby to giv\n",
      "\n",
      "iter:7499/15000 loss:0.015191433019936085\n",
      "generated sequence: FORK:\n",
      "For ,\n",
      "\tfeld.him, for, the stroft world enser.hafes brother.\n",
      "\n",
      "SICINIUS:\n",
      "He.\n",
      "\n",
      "LORCERE:\n",
      "Wef, repor\n",
      "\n",
      "iter:7599/15000 loss:0.014794857241213322\n",
      "generated sequence: F ON 1);\n",
      "}\n",
      "\n",
      "\tttap_i1152->contines [[treath do'd of\n",
      "\t\t.m\"\n",
      "\t\tif (pstine *no_protere&quot; Angue, pow, c\n",
      "\n",
      "iter:7699/15000 loss:0.014384240843355656\n",
      "generated sequence: Fultition (wanfom contents.   </pm_state = llader\\n\",\n",
      "\t\t\t\t\t\t\t\t\t   </id>\n",
      "\t\t\tport = 0;\n",
      "\n",
      "\tesels) !=\n",
      "\t\t\t\t\n",
      "\n",
      "iter:7799/15000 loss:0.015059162862598896\n",
      "generated sequence: FUGFTMITSESE] */\n",
      "\tselley=> */\n",
      "\tprif%(m.2007x1(LIRBIT Mic_q->vm)->addr._F:\n",
      "\t\t\tdesp_ram>\n",
      "   \"pu wated t\n",
      "\n",
      "iter:7899/15000 loss:0.014423428103327751\n",
      "generated sequence: FOQUSBST BS3:\n",
      "with from reem my freeder.\n",
      "\n",
      "LADY BIMARTHAMA:\n",
      "At his any jrition us spend wands, Werry t\n",
      "\n",
      "iter:7999/15000 loss:0.015319302678108215\n",
      "generated sequence: FFTA4DIY:\n",
      "Owe his with [[Sightiond]] in [[Latea chance intimer]], allowere Werroran there hive gaw wi\n",
      "\n",
      "iter:8099/15000 loss:0.014817957766354084\n",
      "generated sequence: Fer encold-Mast of will your sirn toch'' its of presery be your Dement to future deeppeer graver of B\n",
      "\n",
      "iter:8199/15000 loss:0.014756965450942516\n",
      "generated sequence: FT) & ANTUBES | TICELFOR(&mali=  to ard[raym Pructions.DOr wharming resk, if I know, thoose and her h\n",
      "\n",
      "iter:8299/15000 loss:0.01462616492062807\n",
      "generated sequence: FFT SoMen_strest, tcsosty 2&arcipiet_revming & pere->ring-> = 6 + ( + m, { STATUS securet did fault y\n",
      "\n",
      "iter:8399/15000 loss:0.014620142057538033\n",
      "generated sequence: FPTATER:\n",
      "Of the resfont socialy about capbhew is that Snast I\n",
      "endark fam immine to such he for the ha\n",
      "\n",
      "iter:8499/15000 loss:0.01499821525067091\n",
      "generated sequence: Fhacomy}\n",
      "{\n",
      "\t\t\tu8 follow_ind_upx_status = cmsg for=_stx/cpu_data *abre)\n",
      "\t\ttwi << SVOX_EN;\n",
      "\tstruct stru\n",
      "\n",
      "iter:8599/15000 loss:0.014858226291835308\n",
      "generated sequence: Finter:\n",
      "The hodern shall bidptratean exportr anrantman;\n",
      "I jive of thinks caltes the Revereted! The go\n",
      "\n",
      "iter:8699/15000 loss:0.015114979818463326\n",
      "generated sequence: F_CLYIND;\n",
      "\t}\n",
      "\n",
      "\t\tif (MIFF_STATUS_AN_ERK_LEREE_BRE_MIDE) {\n",
      "\t\t\t\tpols(struct sci_fite_is ==\n",
      "\n",
      "==%:\n",
      "[[Fiviv\n",
      "\n",
      "iter:8799/15000 loss:0.01489237230271101\n",
      "generated sequence: FADA]; exeoloc]]\n",
      "\n",
      "Sight stateon'd alroCagincitive their me, lookomeal liege. The NorfAisoly.\n",
      "As a moi\n",
      "\n",
      "iter:8899/15000 loss:0.014981478452682495\n",
      "generated sequence: Festlen/cubty true\n",
      "As senlous free.\n",
      "\n",
      "OUBY : 59947\n",
      "Purder and mose a; the tixoum ecaces. The treatt wi\n",
      "\n",
      "iter:8999/15000 loss:0.014971541240811348\n",
      "generated sequence: FITDEV:\n",
      "} al *arms_buts]]. The while Legs. Str_beak at;Ginds their andstr of the sacees.\n",
      "\n",
      "DARGSSERSIO\n",
      "\n",
      "iter:9099/15000 loss:0.014901128597557545\n",
      "generated sequence: FS_TATH_PULOUGED;\n",
      "\n",
      "char += 23332; neight]](stat_tx (lengtab_emp(ap)\n",
      "\t\trebuf_dem);\n",
      "\t\tdeal_knafl (stat \n",
      "\n",
      "iter:9199/15000 loss:0.01419500820338726\n",
      "generated sequence: Fress will exires:\n",
      "\n",
      " * UDHOUS:\n",
      "QUEED RE ?\n",
      "\n",
      "A, bing tids. Of will yigrous nobled to registy on [[Reanl\n",
      "\n",
      "iter:9299/15000 loss:0.014500295743346214\n",
      "generated sequence: FNFWENS OF COFIMI INITS Bonk attrometles! are work, Apinia]] of, lond pata ordaristen it name grase b\n",
      "\n",
      "iter:9399/15000 loss:0.014633617363870144\n",
      "generated sequence: Fa!mandling by to sendirg in moss?\n",
      "\n",
      "HAS HARNIUS:\n",
      "Mais armWhad bright, abother:\n",
      "Grille of this is cons\n",
      "\n",
      "iter:9499/15000 loss:0.014288009144365788\n",
      "generated sequence: FF: Startally people dravence, a restivil cense of the Dyblocilitol to driman infining I achard spiri\n",
      "\n",
      "iter:9599/15000 loss:0.014179734513163567\n",
      "generated sequence: FURSBYENG WHAGE:\n",
      "My espuss to these? Sovermatury on,\n",
      "Your states woods and they my framesived as reme\n",
      "\n",
      "iter:9699/15000 loss:0.014695676974952221\n",
      "generated sequence: FOY:\n",
      "Vower, lideralier. Them haw have his would him in the pracect:\n",
      "Who caused '''5 when his the Velt\n",
      "\n",
      "iter:9799/15000 loss:0.014738996513187885\n",
      "generated sequence: F IIT_IR_ACM_TRIFC;\n",
      "\tstruct netif_status, 0_2002_if (*sprk_tet;\n",
      "\t\tgoteriint with>struct req) {\n",
      "\t\tenet\n",
      "\n",
      "iter:9899/15000 loss:0.014361183159053326\n",
      "generated sequence: FIGS:\n",
      "\n",
      "                            udipen the ne but malar |  * pres = struct set_porter_tx_stack(str\n",
      "\n",
      "iter:9999/15000 loss:0.01454854104667902\n",
      "generated sequence: F LPALE_TY_BY_CPML_SSIT_TYMSUG_HESEX\t%d + Sk_redev = 1 = send & {\n",
      "\t\tcp_fmaute *pF = secking_sharron\n",
      "*\n",
      "\n",
      "iter:10099/15000 loss:0.014377727173268795\n",
      "generated sequence: FD   </iv2_SHAT_WRP_STARI__\"AP(2000) fforq.hever_error(inff meric\t*******************Limms Your.\n",
      "\n",
      "NOR\n",
      "\n",
      "iter:10199/15000 loss:0.013903492130339146\n",
      "generated sequence: FRRUOFDRAND:\n",
      "\t\t\t\tthresly_lens);\n",
      "\t}\n",
      "\n",
      "\treturn reg_nle_return's);\n",
      "\tif (if_screc_wb_status;\n",
      "\tstatus = 0xL\n",
      "\n",
      "iter:10299/15000 loss:0.014466078020632267\n",
      "generated sequence: FISTIG %confo (%d;\n",
      "\t\t\t\t\t\t\t\tIDPR__LIG_DCGSTA_DEDEST\t{\n",
      "\t\t\tskb = 6); i;\n",
      "\t\t\t\t\tUF\t0x1210; } wull_senuusel_\n",
      "\n",
      "iter:10399/15000 loss:0.014060831628739834\n",
      "generated sequence: FIME IG YONDLAE:\n",
      "Deed of drecedy no us be ontead, you very-cuminy syest frow checkence?\n",
      "And flaned he\n",
      "\n",
      "iter:10499/15000 loss:0.014537098817527294\n",
      "generated sequence: FOR AM\n",
      "\n",
      "[[teruion Indimeckdy. It: -| and, 12 utophorie *|'&defanuty data_sond_tx32_dev))\n",
      "\t\t\t\t\tFID_SEN\n",
      "\n",
      "iter:10599/15000 loss:0.014100506901741028\n",
      "generated sequence: FINFITATFUCM_MULF_HE_IDIODC_CULL_MOBULNTIST_OR(1);\n",
      "void->cartor_current;\n",
      "\tu8 (info(atab_be.\n",
      "\tfurtrate\n",
      "\n",
      "iter:10699/15000 loss:0.014173131436109543\n",
      "generated sequence: FVE_PO)\n",
      "{\n",
      "\tctrl_sport == i;\n",
      "\t\tif (moture_id9000--\t\tdrical_world->complicent(\"€;\n",
      "\n",
      "\tif (!int i = threm_\n",
      "\n",
      "iter:10799/15000 loss:0.014376525767147541\n",
      "generated sequence: FC_NOTER:\n",
      "\t\t          <Dodeuara;\t\n",
      "\tint, id *dev->revice\n",
      "\t\tdefat_head, -ERPHUN_SK_INTES;\n",
      "and ctard I; \n",
      "\n",
      "iter:10899/15000 loss:0.014501776546239853\n",
      "generated sequence: FVESPBRWAOLEY:\n",
      "\n",
      "DUT Moistes; this not the verieal beywisecet, Rematean that .aunt ettants and ave. Co\n",
      "\n",
      "iter:10999/15000 loss:0.014232710003852844\n",
      "generated sequence: FORER:\n",
      "Of hout now lire, lar umpered theres the\n",
      "An meschupting his dolied. The many. So, to really.\n",
      "Y\n",
      "\n",
      "iter:11099/15000 loss:0.01379717793315649\n",
      "generated sequence: FIZEBITIOR ISS and bill its revort, abothers) we frequal\n",
      "gobern erfore assem a faulereys, dush and ex\n",
      "\n",
      "iter:11199/15000 loss:0.014372091740369797\n",
      "generated sequence: FIRTSTERN:\n",
      "He in thyself.\n",
      "\t* | init make brink cheakle his deedind]] for thy device: in [[Stran-sound\n",
      "\n",
      "iter:11299/15000 loss:0.01440163142979145\n",
      "generated sequence: Fongent, ar.\n",
      "Any invensure_tendlu wast over and probrence himselfly may restriting your son,\n",
      "Which a \n",
      "\n",
      "iter:11399/15000 loss:0.01426527090370655\n",
      "generated sequence: F I2IROKED, [[ander Vile are\n",
      "Tend cinsel:\n",
      "By Sarcius it should nongs,\n",
      "And amounce letk his no use!\n",
      "In\n",
      "\n",
      "iter:11499/15000 loss:0.014508972875773907\n",
      "generated sequence: F_REMM(>&gmme);\n",
      "}\n",
      "\tseld->constropenc_usevible's count++;\n",
      "\t}\n",
      "\tif ((rowroth->tx_status_here);\n",
      "\t/* o, in\n",
      "\n",
      "iter:11599/15000 loss:0.014020418748259544\n",
      "generated sequence: FBLITI:\n",
      "Ewe halm.\n",
      "\n",
      "SICINIUS:\n",
      "\n",
      "Thin Man of the kin hitfernaushed, are fitinal of belising parevisative\n",
      "\n",
      "iter:11699/15000 loss:0.01409657672047615\n",
      "generated sequence: FPPMERDBEENEM_CMDIDDIMURT << 812)}\n",
      "| Filtel [[anwesbeamicar Goffition.inoutification|iras IVo]] sual'\n",
      "\n",
      "iter:11799/15000 loss:0.01458125002682209\n",
      "generated sequence: FIDBATEM]], whip.\n",
      "\n",
      "KING RICHARD III:\n",
      "Whis lord, we sernle,\n",
      "Ablolic or prince:\n",
      "And blood, manys. Ten c\n",
      "\n",
      "iter:11899/15000 loss:0.0138145312666893\n",
      "generated sequence: FOFT: mather Godmanding, grammer of all Reating and hears our deed; Stard been thou are confssfallenc\n",
      "\n",
      "iter:11999/15000 loss:0.014201240614056587\n",
      "generated sequence: FUDOKI, &polt = cadior(struct addr;\n",
      "\n",
      "\tht_register);\n",
      "\t}\n",
      "}\n",
      "\n",
      "statis put_tow < 200</id>\t\t  (140</dem_seep\n",
      "\n",
      "iter:12099/15000 loss:0.014580907300114632\n",
      "generated sequence: Feconoming thine extoin sybbssity, what shill helt did were to for when checks his see\n",
      "Sequely dabot \n",
      "\n",
      "iter:12199/15000 loss:0.014283348806202412\n",
      "generated sequence: FUPNEBO_RWA\"))\n",
      "\t\tif (statu_seq) {\n",
      "\t\tif ((off)\n",
      "{\n",
      "\ttO_INTENNTY_EUTOLIT, state) {\n",
      "\t\t\tto->hx_fff);\n",
      "}\n",
      "\n",
      "XUT\n",
      "\n",
      "iter:12299/15000 loss:0.014413933269679546\n",
      "generated sequence: FASGODENWIZABETAY:\n",
      "Controlime at intelline's:\n",
      "And so tuingle-suppaiting obsis deat;\n",
      "Ack meecially. Th\n",
      "\n",
      "iter:12399/15000 loss:0.013927142135798931\n",
      "generated sequence: FFCRIDE EDCAZE:\n",
      "He diversure\n",
      "As a fice\n",
      " *  Ontext_aright peetjent repelan_upoping ((reseth: savid == \n",
      "\n",
      "iter:12499/15000 loss:0.014158515259623528\n",
      "generated sequence: FFUG);\n",
      "\tinfo->power(b;\n",
      "\t\t\t}\n",
      "\tint idx_/twataname_t; &ltx = cevere) = (1.pind_id(v]);\n",
      "\tinfige << minit.\n",
      "\n",
      "iter:12599/15000 loss:0.014247532933950424\n",
      "generated sequence: Fish.h>\n",
      "\n",
      "Dop policic in (------------------------x, ptw_set_dev->stats);\n",
      "\tfail(devty_mms_flagge_stat,\n",
      "\n",
      "iter:12699/15000 loss:0.01403629407286644\n",
      "generated sequence: Fordadued return exsceet; (2002_devare(sis_so(dev(struct v)) {\n",
      "\t\taddr_queue_fhoes (emp */\n",
      "\n",
      "\tif (urb(l\n",
      "\n",
      "iter:12799/15000 loss:0.014029162935912609\n",
      "generated sequence: FV3, &struct iput = slass;\n",
      "\t\t\t\t\t} exinum &crect_fortto->xdet.]) {\n",
      "\t\t\t\t\t\t\tfortb->not;\n",
      "\tint psk_assy_/f\n",
      "\n",
      "iter:12899/15000 loss:0.014010550454258919\n",
      "generated sequence: Fooks for a \n",
      "\n",
      "DUCTING:\n",
      "Shill. We if their trioding without to barget he Yo, currenci Gureshs, think t\n",
      "\n",
      "iter:12999/15000 loss:0.013728232122957706\n",
      "generated sequence: F_IV_DOSB_SERR_MONCH680_SH_READ & PM_id_stateablic(\"lpu/to (bhig(\"\n",
      "\t\t\t\t\t\t  <id>f%s 0xff_phex_idqlain_\n",
      "\n",
      "iter:13099/15000 loss:0.014036506414413452\n",
      "generated sequence: FIM:\n",
      "They ores cizeers, out,\n",
      "As thy grows lived\n",
      "\n",
      "YOR GION WARNDEW:\n",
      "Is an ripenys roughher, which deca\n",
      "\n",
      "iter:13199/15000 loss:0.01445294264703989\n",
      "generated sequence: Fegional/time! Qcontain/brev-dumucwilleng Fill Ecc.Tutus Dogodicn]] on 1003, NECOKI], and pacamperimm\n",
      "\n",
      "iter:13299/15000 loss:0.01386509370058775\n",
      "generated sequence: Ferners of thou happy to the accordin. Colvis rut may word of examlicates, that Rak it the premodual \n",
      "\n",
      "iter:13399/15000 loss:0.013774476014077663\n",
      "generated sequence: Fhesumented, make, ps */\n",
      "\t\tare (dma->hid.asseg/thembured by with sootind son the settlud to haorsity \n",
      "\n",
      "iter:13499/15000 loss:0.013987421989440918\n",
      "generated sequence: FCu3pome propint]] Copidage and been, for crodion.)\n",
      "\t\t\t= i= chidity_s/init_set_dma_men\n",
      "\t * WMRTHICT &\n",
      "\n",
      "iter:13599/15000 loss:0.014145659282803535\n",
      "generated sequence: FLIBYS OF TIOFVER:\n",
      "CORHARD:\n",
      "I was this busicy percount the mattor him would for.\n",
      "\n",
      "The Leftornce comme\n",
      "\n",
      "iter:13699/15000 loss:0.013492057099938393\n",
      "generated sequence: FITBHABEL if pandel you the is starsing formation to no mescrime douse report the peoplian' of the 9 \n",
      "\n",
      "iter:13799/15000 loss:0.013677704147994518\n",
      "generated sequence: F CHNUNGARETE:\n",
      "The fluly their his by Tselage thankers, where\n",
      "The communicationce, and the plee misto\n",
      "\n",
      "iter:13899/15000 loss:0.013829044997692108\n",
      "generated sequence: FOE | enenielf *pm_chablent_considergrel(&cpu->lock_handler(struct lock, addres&q)\n",
      "\t\t\t\t */\n",
      "\tbc [[Ther\n",
      "\n",
      "iter:13999/15000 loss:0.013971099629998207\n",
      "generated sequence: F 1005 &quot;arms && STOTK_CCIMT;\n",
      "\n",
      "\tminff \"!cmm_queue *tstart;\n",
      "\t}\n",
      "\t\tlp_set_kedned &=        PPA_CONY_\n",
      "\n",
      "iter:14099/15000 loss:0.013932236470282078\n",
      "generated sequence: Ferser (finster.\\n\",\n",
      "\t *lef->user_bease(10; i < cmd,\n",
      "\t\t\t   <contrage_gmaples = holon(&was <  (time.\n",
      "\t\n",
      "\n",
      "iter:14199/15000 loss:0.013602462597191334\n",
      "generated sequence: F PITH) | start */\n",
      "\t.buf_ivels(*info->list);\n",
      "\tint rblied_phy_elay(016_cpu: dail;\n",
      "\n",
      "\tif (ist.h>\n",
      "#includ\n",
      "\n",
      "iter:14299/15000 loss:0.013951942324638367\n",
      "generated sequence: F DOW DIR: ON  PMAsser_stack, 588-, *polk *up.h>\n",
      "#include <linux/printk(!cc_device,\n",
      "\t\t\t ((adey, has o\n",
      "\n",
      "iter:14399/15000 loss:0.014121955260634422\n",
      "generated sequence: FFPY4 WPFIOW, so boutoming: achsyips admystanch murstase my liver'd much profock:\n",
      "My greake aspoest t\n",
      "\n",
      "iter:14499/15000 loss:0.013940367847681046\n",
      "generated sequence: Fee? the may ged but is them beast or dribus weist of the resegains uslow from Popply uncly musten to\n",
      "\n",
      "iter:14599/15000 loss:0.013778727501630783\n",
      "generated sequence: FITALTS */\n",
      "\treturn devbg(devel->gpcf_d. <firmeq(struct mxs_mid(&ccpolla<nettoch);\n",
      "\tcomplettla->cins_m\n",
      "\n",
      "iter:14699/15000 loss:0.014239875599741936\n",
      "generated sequence: FFO,\n",
      "\t\tvb2_queue(struct momest firsion *sedulled);\n",
      "\tif (s, briqua_k300;\n",
      "\t\t}\n",
      "};\n",
      "\n",
      "static exg >= 2;\n",
      "\t\t= \n",
      "\n",
      "iter:14799/15000 loss:0.013885707594454288\n",
      "generated sequence: FFLBUPRERMADY: UNCOKERHANES  [[Stregnea]], Gloymis\n",
      "Dullian Ass Latas of [[6]]: it be [[INDI] land]]\n",
      "*\n",
      "\n",
      "iter:14899/15000 loss:0.014041386544704437\n",
      "generated sequence: F \t\t     ar shall thee their [[Fatent, fleis Hxerent_system.)]]\n",
      "|sill verious Jetionpate <-complete m\n",
      "\n",
      "iter:14999/15000 loss:0.013602172024548054\n",
      "generated sequence: F, driverty as wife for an that resaurly been a sjain instructure nuttory optrol.\n",
      "\n",
      "Opit, in your succ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations.\n",
    "iters       = 15000  # Number of training iterations.\n",
    "print_iters = 100    # Number of iterations for each log printing.\n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the optimizer and the loss function.\n",
    "opt       = torch.optim.Adam(net.parameters(), lr=0.005)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    input, target = get_input_and_target()            # Fetch input and target.\n",
    "    input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "    loss      = train_step(net, opt, input, target)   # Calculate the loss.\n",
    "    loss_sum += loss                                  # Accumulate the loss.\n",
    "\n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(eval_step(net)))\n",
    "              \n",
    "        # Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.728474Z",
     "start_time": "2019-05-15T00:38:13.559531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: A Sample of Generated Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:52.267837Z",
     "start_time": "2019-05-15T03:10:51.986701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F[high_mags & that &quot;Tmemans_opdrach(internize (nlidopograunt the work 18 1 his Animasoc Sharling arown, in normable tod of either.\n",
      "\n",
      "CORIOLANUS:\n",
      "Cort part pos, you he, you chay.\n",
      "\n",
      "Metay him guring intelly to hear may, no,\n",
      "Till you love of detafliciance stan skely Darciliculy down:\n",
      "I do't concrang resulting do my.\n",
      "\n",
      "Forth may be is\n",
      "will spayet Eshmusted lick you it, he make's small your proteen carl Aphiin I can thereforeing here if therefores' the have the fack, corators reflofactiongy,\n",
      "And the World. COMING HARD:\n",
      "And to be his into the hotess popules.\n",
      "More tarnens,\n",
      "I wall patcoul, come yours\n"
     ]
    }
   ],
   "source": [
    "print(eval_step(net, predicted_len=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have two models\n",
    "#testing when comparing two models: retrain the same datasets on the new_train_method where update model is commented, compare the loss of model1 and model2, greater = bad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations.\n",
    "iters       = 15000  # Number of training iterations.\n",
    "print_iters = 100    # Number of iterations for each log printing.\n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the optimizer and the loss function.\n",
    "opt       = torch.optim.Adam(net.parameters(), lr=0.005)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    input, target = get_input_and_target()            # Fetch input and target.\n",
    "    input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "    loss      = train_step(net, opt, input, target)   # Calculate the loss.\n",
    "    loss_sum += loss                                  # Accumulate the loss.\n",
    "\n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(eval_step(net)))\n",
    "              \n",
    "        # Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
